{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "tight-barrier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Name                               Website Link\n",
      "0                   Causa                   https://www.causadc.com/\n",
      "1                  Lut√®ce                  https://www.lutecedc.com/\n",
      "2                    Albi                    https://www.albidc.com/\n",
      "3              The Dabney                     https://thedabney.com/\n",
      "4        Beloved Barbecue  https://www.lovemakoto.com/menus#bbq-menu\n",
      "..                    ...                                        ...\n",
      "100      Thompson Italian               https://thompsonitalian.com/\n",
      "101           Tremolo Bar                https://www.tremolobar.com/\n",
      "102                Tsehay                  https://www.tsehaydc.com/\n",
      "103  Unconventional Diner       https://www.unconventionaldiner.com/\n",
      "104    Virginia's Darling          https://www.virginiasdarling.com/\n",
      "\n",
      "[105 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Read the HTML file\n",
    "with open(\"/Users/tommyhadeed/Desktop/100_2024.html\", \"r\", encoding=\"utf-8\") as f:\n",
    "    html_content = f.read()\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "# Initialize lists to store extracted data\n",
    "names = []\n",
    "website_links = []\n",
    "\n",
    "# Find all list items with class 'ais-Hits-item'\n",
    "list_items = soup.find_all('li', class_='ais-Hits-item')\n",
    "\n",
    "# Loop through each list item\n",
    "for item in list_items:\n",
    "    # Find the element containing the name\n",
    "    name_element = item.find('span', class_='tw-font-bold')\n",
    "    if name_element:\n",
    "        name = name_element.text.strip()  # Extract the name\n",
    "        names.append(name)\n",
    "    else:\n",
    "        names.append(None)  # Append None if name not found\n",
    "    \n",
    "    # Find the 'Visit Website' link\n",
    "    link_elements = item.find_all('a')\n",
    "    website_link = None\n",
    "    for link_element in link_elements:\n",
    "        if link_element.text.strip() == 'Visit Website':\n",
    "            website_link = link_element['href']\n",
    "            break  # Stop searching once the link is found\n",
    "    website_links.append(website_link)\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Name': names,\n",
    "    'Website Link': website_links\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "economic-murder",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"/Users/tommyhadeed/Desktop/output.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-brick",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
